{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN\n",
    "- 참고논문: [Image Super-Resolution Using Deep Convolutional Networks](https://arxiv.org/pdf/1501.00092)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import time\n",
    "import PIL.Image as pil_image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = './checkpoint'\n",
    "train_db_dir = './DB/train'\n",
    "log_dir = './log'\n",
    "\n",
    "lr = 0.0001     # cf. lr = 1e-4\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "num_workers = 0\n",
    "\n",
    "device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 파라미터 저장/불러오기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ckpt_dir, net, optim, postfix):      # ckpt_dir: checkpoint를 저장할 경로, net, optim, epoch\n",
    "    if not os.path.exists(ckpt_dir):    # ckpt_dir이 존재하는지 확인하는 함수\n",
    "        os.makedirs(ckpt_dir)           # 디렉토리를 만들어주는 함수\n",
    "\n",
    "    torch.save({'net': net.state_dict(),        # 네트워크에 있는 변수들\n",
    "                'optim': optim.state_dict()},   # optimizer에 있는 변수들\n",
    "               './%s/model_epoch%s.pth' % (ckpt_dir, str(postfix)))\n",
    "\n",
    "def load(filename, net, optim):\n",
    "    dict_model = torch.load(filename)\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "\n",
    "    return net, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 네트워크 및 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(SRCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=9,\n",
    "                               padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=5,\n",
    "                               padding=5 // 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, \n",
    "                               out_channels=num_channels, \n",
    "                               kernel_size=5,\n",
    "                               padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SRCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 정확도 측정 함수 (PSNR) 선언\n",
    "PSNR: [wiki](https://ko.wikipedia.org/wiki/%EC%B5%9C%EB%8C%80_%EC%8B%A0%ED%98%B8_%EB%8C%80_%EC%9E%A1%EC%9D%8C%EB%B9%84)\n",
    "\n",
    "$\\textrm{PSNR}=10\\cdot\\log{\\left(\\frac{\\textrm{MAX}^2}{\\textrm{MSE}}\\right)}$\n",
    "\n",
    "$\\textrm{MAX}$: tensor가 가질 수 있는 최대값\n",
    "\n",
    "$\\textrm{MSE}$: Mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(image1, image2):\n",
    "    max_val = 1.\n",
    "    mse = torch.mean((image1 - image2) ** 2)\n",
    "    psnr = 10. * torch.log10((max_val ** 2) / mse)\n",
    "    return psnr.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset, data loader 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 image_dir,\n",
    "                 input_transform=None, \n",
    "                 target_transform=None, \n",
    "                 db_type='train'):\n",
    "        super(SRDataset, self).__init__()\n",
    "        \n",
    "        lr_dir = os.path.join(image_dir, \"lr/\")     # low-resolution image (input)\n",
    "        hr_dir = os.path.join(image_dir, \"hr/\")     # high-resolution image (label)\n",
    "        \n",
    "        self.lr_list = [\n",
    "            os.path.join(lr_dir, f) for f in os.listdir(lr_dir)]\n",
    "        self.hr_list = [\n",
    "            os.path.join(hr_dir, f) for f in os.listdir(hr_dir)]\n",
    "        \n",
    "        self.lr_list.sort()\n",
    "        self.hr_list.sort()\n",
    "        \n",
    "        total_len = len(self.hr_list)\n",
    "        train_len = round(total_len * 0.9)\n",
    "        \n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.db_type = db_type\n",
    "        \n",
    "        if self.db_type is 'train':\n",
    "            self.lr_list = self.lr_list[:train_len]\n",
    "            self.hr_list = self.hr_list[:train_len]\n",
    "        elif self.db_type is 'val':\n",
    "            self.lr_list = self.lr_list[train_len:]\n",
    "            self.hr_list = self.hr_list[train_len:]\n",
    "\n",
    "        self.crop_size = 33\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_image = pil_image.open(self.lr_list[idx])\n",
    "        hr_image = pil_image.open(self.hr_list[idx])\n",
    "        \n",
    "        # Transform images\n",
    "        if self.input_transform is not None:\n",
    "            lr_image = self.input_transform(lr_image)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            hr_image = self.target_transform(hr_image)\n",
    "\n",
    "        if self.db_type is 'train':\n",
    "            # Random crop\n",
    "            lr_image, hr_image = self.random_crop(lr_image, hr_image)\n",
    "        \n",
    "        return lr_image, hr_image\n",
    "            \n",
    "    def random_crop(self, input, target):\n",
    "        h = input.size(-2)\n",
    "        w = input.size(-1)\n",
    "                \n",
    "        rand_h = torch.randint(h - self.crop_size, [1, 1])\n",
    "        rand_w = torch.randint(w - self.crop_size, [1, 1])\n",
    "        \n",
    "        input = input[:, rand_h:rand_h + self.crop_size, rand_w:rand_w + self.crop_size]\n",
    "        target = target[:, rand_h:rand_h + self.crop_size, rand_w:rand_w + self.crop_size]\n",
    "        \n",
    "        return input, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hr_list)\n",
    "\n",
    "\n",
    "input_transform = transforms.Compose(\n",
    "                    [transforms.ToTensor()])\n",
    "target_transform = transforms.Compose(\n",
    "                    [transforms.ToTensor()])\n",
    "\n",
    "train_dataset = SRDataset(train_db_dir,\n",
    "                          input_transform=input_transform,\n",
    "                          target_transform=target_transform,\n",
    "                          db_type='train')\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              drop_last=True)\n",
    "val_dataset = SRDataset(train_db_dir, \n",
    "                        input_transform=input_transform,\n",
    "                        target_transform=target_transform,\n",
    "                        db_type='val')\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training & validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0/100 | BATCH 1/346 | LOSS: 0.265382\n",
      "TRAIN: EPOCH 0/100 | BATCH 11/346 | LOSS: 0.181070\n",
      "TRAIN: EPOCH 0/100 | BATCH 21/346 | LOSS: 0.119643\n",
      "TRAIN: EPOCH 0/100 | BATCH 31/346 | LOSS: 0.091432\n",
      "TRAIN: EPOCH 0/100 | BATCH 41/346 | LOSS: 0.075563\n",
      "TRAIN: EPOCH 0/100 | BATCH 51/346 | LOSS: 0.064887\n",
      "TRAIN: EPOCH 0/100 | BATCH 61/346 | LOSS: 0.057650\n",
      "TRAIN: EPOCH 0/100 | BATCH 71/346 | LOSS: 0.051923\n",
      "TRAIN: EPOCH 0/100 | BATCH 81/346 | LOSS: 0.047460\n",
      "TRAIN: EPOCH 0/100 | BATCH 91/346 | LOSS: 0.043726\n",
      "TRAIN: EPOCH 0/100 | BATCH 101/346 | LOSS: 0.040757\n",
      "TRAIN: EPOCH 0/100 | BATCH 111/346 | LOSS: 0.038043\n",
      "TRAIN: EPOCH 0/100 | BATCH 121/346 | LOSS: 0.035734\n",
      "TRAIN: EPOCH 0/100 | BATCH 131/346 | LOSS: 0.033609\n",
      "TRAIN: EPOCH 0/100 | BATCH 141/346 | LOSS: 0.031787\n",
      "TRAIN: EPOCH 0/100 | BATCH 151/346 | LOSS: 0.030169\n",
      "TRAIN: EPOCH 0/100 | BATCH 161/346 | LOSS: 0.028690\n",
      "TRAIN: EPOCH 0/100 | BATCH 171/346 | LOSS: 0.027427\n",
      "TRAIN: EPOCH 0/100 | BATCH 181/346 | LOSS: 0.026259\n",
      "TRAIN: EPOCH 0/100 | BATCH 191/346 | LOSS: 0.025156\n",
      "TRAIN: EPOCH 0/100 | BATCH 201/346 | LOSS: 0.024270\n",
      "TRAIN: EPOCH 0/100 | BATCH 211/346 | LOSS: 0.023411\n",
      "TRAIN: EPOCH 0/100 | BATCH 221/346 | LOSS: 0.022562\n",
      "TRAIN: EPOCH 0/100 | BATCH 231/346 | LOSS: 0.021860\n",
      "TRAIN: EPOCH 0/100 | BATCH 241/346 | LOSS: 0.021121\n",
      "TRAIN: EPOCH 0/100 | BATCH 251/346 | LOSS: 0.020477\n",
      "TRAIN: EPOCH 0/100 | BATCH 261/346 | LOSS: 0.019895\n",
      "TRAIN: EPOCH 0/100 | BATCH 271/346 | LOSS: 0.019359\n",
      "TRAIN: EPOCH 0/100 | BATCH 281/346 | LOSS: 0.018869\n",
      "TRAIN: EPOCH 0/100 | BATCH 291/346 | LOSS: 0.018439\n",
      "TRAIN: EPOCH 0/100 | BATCH 301/346 | LOSS: 0.018011\n",
      "TRAIN: EPOCH 0/100 | BATCH 311/346 | LOSS: 0.017604\n",
      "TRAIN: EPOCH 0/100 | BATCH 321/346 | LOSS: 0.017226\n",
      "TRAIN: EPOCH 0/100 | BATCH 331/346 | LOSS: 0.016852\n",
      "TRAIN: EPOCH 0/100 | BATCH 341/346 | LOSS: 0.016534\n",
      "PSNR of 0th image: 26.203592\n",
      "PSNR of 10th image: 27.652279\n",
      "PSNR of 20th image: 26.982586\n",
      "PSNR of 30th image: 25.115829\n",
      "PSNR of 40th image: 28.306976\n",
      "PSNR of 50th image: 26.736107\n",
      "PSNR of 60th image: 26.634321\n",
      "PSNR of 70th image: 27.501450\n",
      "PSNR of 80th image: 26.346121\n",
      "PSNR of 90th image: 26.589436\n",
      "PSNR of 100th image: 27.369995\n",
      "PSNR of 110th image: 26.628733\n",
      "PSNR of 120th image: 26.737499\n",
      "PSNR of 130th image: 26.655748\n",
      "PSNR of 140th image: 26.394173\n",
      "PSNR of 150th image: 26.384712\n",
      "PSNR of 160th image: 26.027218\n",
      "PSNR of 170th image: 26.758579\n",
      "PSNR of 180th image: 26.812229\n",
      "PSNR of 190th image: 27.591478\n",
      "PSNR of 200th image: 26.971004\n",
      "PSNR of 210th image: 27.596355\n",
      "PSNR of 220th image: 24.641605\n",
      "PSNR of 230th image: 27.936668\n",
      "PSNR of 240th image: 26.844538\n",
      "PSNR of 250th image: 26.934500\n",
      "PSNR of 260th image: 26.415649\n",
      "PSNR of 270th image: 26.874722\n",
      "PSNR of 280th image: 26.673389\n",
      "PSNR of 290th image: 25.491362\n",
      "PSNR of 300th image: 26.870222\n",
      "PSNR of 310th image: 25.810015\n",
      "PSNR of 320th image: 25.459509\n",
      "PSNR of 330th image: 26.484444\n",
      "PSNR of 340th image: 26.608915\n",
      "PSNR of 350th image: 25.790028\n",
      "PSNR of 360th image: 27.939484\n",
      "PSNR of 370th image: 25.048641\n",
      "PSNR of 380th image: 26.530899\n",
      "PSNR of 390th image: 26.665953\n",
      "PSNR of 400th image: 24.134537\n",
      "PSNR of 410th image: 24.354431\n",
      "PSNR of 420th image: 24.643490\n",
      "PSNR of 430th image: 24.849844\n",
      "PSNR of 440th image: 24.115191\n",
      "PSNR of 450th image: 26.527840\n",
      "PSNR of 460th image: 24.114624\n",
      "PSNR of 470th image: 25.299541\n",
      "PSNR of 480th image: 21.288521\n",
      "PSNR of 490th image: 28.883354\n",
      "PSNR of 500th image: 30.466633\n",
      "PSNR of 510th image: 26.687002\n",
      "PSNR of 520th image: 25.691048\n",
      "PSNR of 530th image: 27.547968\n",
      "PSNR of 540th image: 27.356956\n",
      "PSNR of 550th image: 24.418295\n",
      "PSNR of 560th image: 24.753540\n",
      "PSNR of 570th image: 24.617359\n",
      "PSNR of 580th image: 25.643532\n",
      "PSNR of 590th image: 25.553650\n",
      "PSNR of 600th image: 25.951359\n",
      "PSNR of 610th image: 25.975187\n",
      "Validation PSNR: 26.199823\n",
      "TRAIN: EPOCH 1/100 | BATCH 1/346 | LOSS: 0.002383\n",
      "TRAIN: EPOCH 1/100 | BATCH 11/346 | LOSS: 0.004369\n",
      "TRAIN: EPOCH 1/100 | BATCH 21/346 | LOSS: 0.005258\n",
      "TRAIN: EPOCH 1/100 | BATCH 31/346 | LOSS: 0.005542\n",
      "TRAIN: EPOCH 1/100 | BATCH 41/346 | LOSS: 0.005469\n",
      "TRAIN: EPOCH 1/100 | BATCH 51/346 | LOSS: 0.005408\n",
      "TRAIN: EPOCH 1/100 | BATCH 61/346 | LOSS: 0.005322\n",
      "TRAIN: EPOCH 1/100 | BATCH 71/346 | LOSS: 0.005352\n",
      "TRAIN: EPOCH 1/100 | BATCH 81/346 | LOSS: 0.005284\n",
      "TRAIN: EPOCH 1/100 | BATCH 91/346 | LOSS: 0.005217\n",
      "TRAIN: EPOCH 1/100 | BATCH 101/346 | LOSS: 0.005138\n",
      "TRAIN: EPOCH 1/100 | BATCH 111/346 | LOSS: 0.005106\n",
      "TRAIN: EPOCH 1/100 | BATCH 121/346 | LOSS: 0.005084\n",
      "TRAIN: EPOCH 1/100 | BATCH 131/346 | LOSS: 0.005027\n",
      "TRAIN: EPOCH 1/100 | BATCH 141/346 | LOSS: 0.005078\n",
      "TRAIN: EPOCH 1/100 | BATCH 151/346 | LOSS: 0.005101\n",
      "TRAIN: EPOCH 1/100 | BATCH 161/346 | LOSS: 0.005094\n",
      "TRAIN: EPOCH 1/100 | BATCH 171/346 | LOSS: 0.005137\n",
      "TRAIN: EPOCH 1/100 | BATCH 181/346 | LOSS: 0.005142\n",
      "TRAIN: EPOCH 1/100 | BATCH 191/346 | LOSS: 0.005098\n",
      "TRAIN: EPOCH 1/100 | BATCH 201/346 | LOSS: 0.005104\n",
      "TRAIN: EPOCH 1/100 | BATCH 211/346 | LOSS: 0.005097\n",
      "TRAIN: EPOCH 1/100 | BATCH 221/346 | LOSS: 0.005089\n",
      "TRAIN: EPOCH 1/100 | BATCH 231/346 | LOSS: 0.005078\n",
      "TRAIN: EPOCH 1/100 | BATCH 241/346 | LOSS: 0.005046\n",
      "TRAIN: EPOCH 1/100 | BATCH 251/346 | LOSS: 0.005048\n",
      "TRAIN: EPOCH 1/100 | BATCH 261/346 | LOSS: 0.004978\n",
      "TRAIN: EPOCH 1/100 | BATCH 271/346 | LOSS: 0.004984\n",
      "TRAIN: EPOCH 1/100 | BATCH 281/346 | LOSS: 0.004968\n",
      "TRAIN: EPOCH 1/100 | BATCH 291/346 | LOSS: 0.004963\n",
      "TRAIN: EPOCH 1/100 | BATCH 301/346 | LOSS: 0.004983\n",
      "TRAIN: EPOCH 1/100 | BATCH 311/346 | LOSS: 0.005024\n",
      "TRAIN: EPOCH 1/100 | BATCH 321/346 | LOSS: 0.005037\n",
      "TRAIN: EPOCH 1/100 | BATCH 331/346 | LOSS: 0.005053\n",
      "TRAIN: EPOCH 1/100 | BATCH 341/346 | LOSS: 0.005066\n",
      "PSNR of 0th image: 26.577843\n",
      "PSNR of 10th image: 28.060135\n",
      "PSNR of 20th image: 27.291563\n",
      "PSNR of 30th image: 25.368977\n",
      "PSNR of 40th image: 28.676214\n",
      "PSNR of 50th image: 27.054688\n",
      "PSNR of 60th image: 27.038679\n",
      "PSNR of 70th image: 27.903877\n",
      "PSNR of 80th image: 26.679722\n",
      "PSNR of 90th image: 26.966709\n",
      "PSNR of 100th image: 27.814131\n",
      "PSNR of 110th image: 27.106230\n",
      "PSNR of 120th image: 27.082806\n",
      "PSNR of 130th image: 26.954197\n",
      "PSNR of 140th image: 26.712454\n",
      "PSNR of 150th image: 26.725300\n",
      "PSNR of 160th image: 26.396709\n",
      "PSNR of 170th image: 27.140589\n",
      "PSNR of 180th image: 27.222670\n",
      "PSNR of 190th image: 28.060814\n",
      "PSNR of 200th image: 27.360554\n",
      "PSNR of 210th image: 27.943764\n",
      "PSNR of 220th image: 24.928076\n",
      "PSNR of 230th image: 28.388235\n",
      "PSNR of 240th image: 27.250069\n",
      "PSNR of 250th image: 27.311253\n",
      "PSNR of 260th image: 26.759289\n",
      "PSNR of 270th image: 27.194580\n",
      "PSNR of 280th image: 27.034786\n",
      "PSNR of 290th image: 25.825975\n",
      "PSNR of 300th image: 27.205242\n",
      "PSNR of 310th image: 26.133846\n",
      "PSNR of 320th image: 25.825184\n",
      "PSNR of 330th image: 26.827669\n",
      "PSNR of 340th image: 27.001396\n",
      "PSNR of 350th image: 26.107731\n",
      "PSNR of 360th image: 28.243809\n",
      "PSNR of 370th image: 25.304163\n",
      "PSNR of 380th image: 26.938295\n",
      "PSNR of 390th image: 27.000313\n",
      "PSNR of 400th image: 24.362759\n",
      "PSNR of 410th image: 24.615252\n",
      "PSNR of 420th image: 24.794338\n",
      "PSNR of 430th image: 25.073309\n",
      "PSNR of 440th image: 24.395878\n",
      "PSNR of 450th image: 26.962912\n",
      "PSNR of 460th image: 24.316925\n",
      "PSNR of 470th image: 25.562105\n",
      "PSNR of 480th image: 21.448891\n",
      "PSNR of 490th image: 29.286592\n",
      "PSNR of 500th image: 30.936550\n",
      "PSNR of 510th image: 27.114956\n",
      "PSNR of 520th image: 26.084656\n",
      "PSNR of 530th image: 27.880037\n",
      "PSNR of 540th image: 27.651062\n",
      "PSNR of 550th image: 24.755978\n",
      "PSNR of 560th image: 24.966949\n",
      "PSNR of 570th image: 24.845295\n",
      "PSNR of 580th image: 25.926449\n",
      "PSNR of 590th image: 25.861855\n",
      "PSNR of 600th image: 26.209499\n",
      "PSNR of 610th image: 26.187403\n",
      "Validation PSNR: 26.532536\n",
      "TRAIN: EPOCH 2/100 | BATCH 1/346 | LOSS: 0.004512\n",
      "TRAIN: EPOCH 2/100 | BATCH 11/346 | LOSS: 0.003754\n",
      "TRAIN: EPOCH 2/100 | BATCH 21/346 | LOSS: 0.003936\n",
      "TRAIN: EPOCH 2/100 | BATCH 31/346 | LOSS: 0.004103\n",
      "TRAIN: EPOCH 2/100 | BATCH 41/346 | LOSS: 0.004327\n",
      "TRAIN: EPOCH 2/100 | BATCH 51/346 | LOSS: 0.004475\n",
      "TRAIN: EPOCH 2/100 | BATCH 61/346 | LOSS: 0.004512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26908\\3633773987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mloss_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26908\\784423905.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Transform images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mlr_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;31m# handle PIL Image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"I\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"I;16\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"F\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"L\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m             \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ArrayData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    716\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[1;31m# unpack data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "num_train = len(train_dataset) // batch_size\n",
    "\n",
    "writer = SummaryWriter(log_dir='./log')\n",
    "\n",
    "start_t = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    loss_arr = []\n",
    "    \n",
    "    for iter, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(inputs)     # net.forward(input)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()   # G = 0 \n",
    "\n",
    "        loss.backward()     # 그라디언트를 계산\n",
    "\n",
    "        optimizer.step()    # 그라디언트를 사용하여 파라미터를 업데이트\n",
    "\n",
    "        loss_arr += [loss.item()]\n",
    "       \n",
    "        if iter % 10 == 0:\n",
    "            elapsed_time = time.time() - start_t\n",
    "            print('TRAIN(Elapsed: %fs): EPOCH %d/%d | BATCH %d/%d | LOSS: %f' %\n",
    "                (epoch, num_epochs, iter+1, num_train, np.mean(loss_arr)))\n",
    "            start_t = time.time()\n",
    "        \n",
    "    save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='{}'.format(epoch+1))\n",
    "    \n",
    "    model.eval()\n",
    "    psnr_arr = []\n",
    "    \n",
    "    for n, (input, label) in enumerate(val_dataloader):\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(input)\n",
    "            preds = preds.clamp(0.0, 1.0)\n",
    "            \n",
    "        psnr = calculate_psnr(preds, label)\n",
    "        psnr_arr.append(psnr)\n",
    "    \n",
    "    epoch_psnr = np.mean(psnr_arr)\n",
    "    print('PSNR(epoch: %d): %f' % (epoch+1, epoch_psnr))\n",
    "    \n",
    "    if epoch_psnr > best_psnr:\n",
    "        best_psnr = epoch_psnr\n",
    "        best_epoch = epoch\n",
    "        save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='_best')\n",
    "    \n",
    "    # Log on tensorboard\n",
    "    writer.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "    writer.add_scalar('psnr', epoch_psnr, epoch)\n",
    "        \n",
    "writer.close\n",
    "print('best epoch: {}, psnr: {}'.format(best_epoch, best_psnr))\n",
    "save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='_best')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
