{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN\n",
    "- 참고논문: [Image Super-Resolution Using Deep Convolutional Networks](https://arxiv.org/pdf/1501.00092)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import time\n",
    "import PIL.Image as pil_image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = './checkpoint'\n",
    "train_db_dir = './DB/train'\n",
    "# log_dir = './log'\n",
    "\n",
    "lr = 0.0001     # cf. lr = 1e-4\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "num_workers = 0\n",
    "\n",
    "device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 파라미터 저장/불러오기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ckpt_dir, net, optim, postfix):      # ckpt_dir: checkpoint를 저장할 경로, net, optim, epoch\n",
    "    if not os.path.exists(ckpt_dir):    # ckpt_dir이 존재하는지 확인하는 함수\n",
    "        os.makedirs(ckpt_dir)           # 디렉토리를 만들어주는 함수\n",
    "\n",
    "    torch.save({'net': net.state_dict(),        # 네트워크에 있는 변수들\n",
    "                'optim': optim.state_dict()},   # optimizer에 있는 변수들\n",
    "               './%s/model_epoch%s.pth' % (ckpt_dir, str(postfix)))\n",
    "\n",
    "def load(filename, net, optim):\n",
    "    dict_model = torch.load(filename)\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "\n",
    "    return net, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 네트워크 및 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(SRCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=9,\n",
    "                               padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=5,\n",
    "                               padding=5 // 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, \n",
    "                               out_channels=num_channels, \n",
    "                               kernel_size=5,\n",
    "                               padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SRCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 정확도 측정 함수 (PSNR) 선언\n",
    "PSNR: [wiki](https://ko.wikipedia.org/wiki/%EC%B5%9C%EB%8C%80_%EC%8B%A0%ED%98%B8_%EB%8C%80_%EC%9E%A1%EC%9D%8C%EB%B9%84)\n",
    "\n",
    "$\\textrm{PSNR}=10\\cdot\\log{\\left(\\frac{\\textrm{MAX}^2}{\\textrm{MSE}}\\right)}$\n",
    "\n",
    "$\\textrm{MAX}$: tensor가 가질 수 있는 최대값\n",
    "\n",
    "$\\textrm{MSE}$: Mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(image1, image2):\n",
    "    max_val = 1.\n",
    "    mse = torch.mean((image1 - image2) ** 2)\n",
    "    psnr = 10. * torch.log10((max_val ** 2) / mse)\n",
    "    return psnr.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset, data loader 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 image_dir,\n",
    "                 input_transform=None, \n",
    "                 target_transform=None, \n",
    "                 db_type='train'):\n",
    "        super(SRDataset, self).__init__()\n",
    "        \n",
    "        lr_dir = os.path.join(image_dir, \"lr/\")     # low-resolution image (input)\n",
    "        hr_dir = os.path.join(image_dir, \"hr/\")     # high-resolution image (label)\n",
    "        \n",
    "        self.lr_list = [\n",
    "            os.path.join(lr_dir, f) for f in os.listdir(lr_dir)]\n",
    "        self.hr_list = [\n",
    "            os.path.join(hr_dir, f) for f in os.listdir(hr_dir)]\n",
    "        \n",
    "        self.lr_list.sort()\n",
    "        self.hr_list.sort()\n",
    "        \n",
    "        total_len = len(self.hr_list)\n",
    "        train_len = round(total_len * 0.9)\n",
    "        \n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.db_type = db_type\n",
    "        \n",
    "        if self.db_type is 'train':\n",
    "            self.lr_list = self.lr_list[:train_len]\n",
    "            self.hr_list = self.hr_list[:train_len]\n",
    "        elif self.db_type is 'val':\n",
    "            self.lr_list = self.lr_list[train_len:]\n",
    "            self.hr_list = self.hr_list[train_len:]\n",
    "\n",
    "        self.crop_size = 33\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_image = pil_image.open(self.lr_list[idx])\n",
    "        hr_image = pil_image.open(self.hr_list[idx])\n",
    "        \n",
    "        # Transform images\n",
    "        if self.input_transform is not None:\n",
    "            lr_image = self.input_transform(lr_image)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            hr_image = self.target_transform(hr_image)\n",
    "\n",
    "        if self.db_type is 'train':\n",
    "            # Random crop\n",
    "            lr_image, hr_image = self.random_crop(lr_image, hr_image)\n",
    "        \n",
    "        return lr_image, hr_image\n",
    "            \n",
    "    def random_crop(self, input, target):\n",
    "        h = input.size(-2)\n",
    "        w = input.size(-1)\n",
    "                \n",
    "        rand_h = torch.randint(h - self.crop_size, [1, 1])\n",
    "        rand_w = torch.randint(w - self.crop_size, [1, 1])\n",
    "        \n",
    "        input = input[:, rand_h:rand_h + self.crop_size, rand_w:rand_w + self.crop_size]\n",
    "        target = target[:, rand_h:rand_h + self.crop_size, rand_w:rand_w + self.crop_size]\n",
    "        \n",
    "        return input, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hr_list)\n",
    "\n",
    "\n",
    "input_transform = transforms.Compose(\n",
    "                    [transforms.ToTensor()])\n",
    "target_transform = transforms.Compose(\n",
    "                    [transforms.ToTensor()])\n",
    "\n",
    "train_dataset = SRDataset(train_db_dir,\n",
    "                          input_transform=input_transform,\n",
    "                          target_transform=target_transform,\n",
    "                          db_type='train')\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              drop_last=True)\n",
    "val_dataset = SRDataset(train_db_dir, \n",
    "                        input_transform=input_transform,\n",
    "                        target_transform=target_transform,\n",
    "                        db_type='val')\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training & validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "num_train = len(train_dataset) // batch_size\n",
    "\n",
    "# writer = SummaryWriter(log_dir='./log')\n",
    "\n",
    "start_t = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    loss_arr = []\n",
    "    \n",
    "    for iter, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(inputs)     # net.forward(input)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()   # G = 0 \n",
    "\n",
    "        loss.backward()     # 그라디언트를 계산\n",
    "\n",
    "        optimizer.step()    # 그라디언트를 사용하여 파라미터를 업데이트\n",
    "\n",
    "        loss_arr += [loss.item()]\n",
    "       \n",
    "        if iter % 20 == 0:\n",
    "            elapsed_time = time.time() - start_t\n",
    "            print('TRAIN(Elapsed: %fs): EPOCH %d/%d | BATCH %d/%d | LOSS: %f' %\n",
    "                (epoch+1, num_epochs, iter+1, num_train, np.mean(loss_arr)))\n",
    "            start_t = time.time()\n",
    "        \n",
    "    save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='{}'.format(epoch+1))\n",
    "    \n",
    "    model.eval()\n",
    "    psnr_arr = []\n",
    "    \n",
    "    for n, (input, label) in enumerate(val_dataloader):\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(input)\n",
    "            preds = preds.clamp(0.0, 1.0)\n",
    "            \n",
    "        psnr = calculate_psnr(preds, label)\n",
    "        psnr_arr.append(psnr)\n",
    "    \n",
    "    epoch_psnr = np.mean(psnr_arr)\n",
    "    print('PSNR(epoch: %d): %f' % (epoch+1, epoch_psnr))\n",
    "    \n",
    "    if epoch_psnr > best_psnr:\n",
    "        best_psnr = epoch_psnr\n",
    "        best_epoch = epoch\n",
    "        save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='_best')\n",
    "    \n",
    "    # # Log on tensorboard\n",
    "    # writer.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "    # writer.add_scalar('psnr', epoch_psnr, epoch)\n",
    "        \n",
    "# writer.close\n",
    "print('best epoch: {}, psnr: {}'.format(best_epoch, best_psnr))\n",
    "save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='_best')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
