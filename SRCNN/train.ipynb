{"cells":[{"cell_type":"markdown","metadata":{"id":"9P-MXdhhpcyv"},"source":["# SRCNN\n","- 참고논문: [Image Super-Resolution Using Deep Convolutional Networks](https://arxiv.org/pdf/1501.00092)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18364,"status":"ok","timestamp":1654669508720,"user":{"displayName":"김승욱","userId":"08177621807583907944"},"user_tz":-540},"id":"WZX_WWJqpjcD","outputId":"6159f23a-ff65-455c-e806-1bc704ad84c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Colab용 코드, PC에서 수행시에는 제거\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"wFBbbkcdqJcQ"},"source":["# 압축풀기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KR4Q9XrpsV6","outputId":"0611aade-c4a5-420e-c4e2-365c4371eced"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/ai_intro/SRCNN\n","replace test/lr/test_image001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["# DB를 Google Drive에 생성하기 위한 코드, 최초 실행후에는 주석처리\n","%cd /content/drive/MyDrive/ai_intro/SRCNN\n","!unzip -qq \"/content/drive/MyDrive/ai_intro/SRCNN/DB.zip\""]},{"cell_type":"markdown","metadata":{"id":"b4SUOavCpcyy"},"source":["## 1. 필요 라이브러리 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uk0Acpcrpcyz"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision import transforms\n","# from torch.utils.tensorboard import SummaryWriter\n","\n","import time\n","import PIL.Image as pil_image\n","import numpy as np\n","import os"]},{"cell_type":"markdown","metadata":{"id":"8xONrjYWpcy0"},"source":["## 3. 하이퍼 파라미터 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljdCISl4pcy0"},"outputs":[],"source":["root = '/content/drive/MyDrive/ai_intro/SRCNN'  # PC에서는 root = './'로 변경\n","ckpt_dir = os.path.join(root, 'checkpoint')\n","train_db_dir = os.path.join(root, 'DB/train')\n","# log_dir = './log'\n","\n","lr = 0.0001     # cf. lr = 1e-4\n","batch_size = 32\n","num_epochs = 50\n","num_workers = 2\n","\n","device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"KOyTPmGspcy1"},"source":["## 4. 파라미터 저장/불러오기 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfgc-3ZWpcy1"},"outputs":[],"source":["def save(ckpt_dir, net, optim, postfix):      # ckpt_dir: checkpoint를 저장할 경로, net, optim, epoch\n","    if not os.path.exists(ckpt_dir):    # ckpt_dir이 존재하는지 확인하는 함수\n","        os.makedirs(ckpt_dir)           # 디렉토리를 만들어주는 함수\n","\n","    torch.save({'net': net.state_dict(),        # 네트워크에 있는 변수들\n","                'optim': optim.state_dict()},   # optimizer에 있는 변수들\n","               '%s/model_epoch%s.pth' % (ckpt_dir, str(postfix)))\n","\n","def load(filename, net, optim):\n","    dict_model = torch.load(filename)\n","\n","    net.load_state_dict(dict_model['net'])\n","    optim.load_state_dict(dict_model['optim'])\n","\n","    return net, optim"]},{"cell_type":"markdown","metadata":{"id":"_5M48F8Qpcy2"},"source":["## 5. 네트워크 및 손실함수 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HM9wXnb9pcy2"},"outputs":[],"source":["class SRCNN(nn.Module):\n","    def __init__(self, num_channels=3):\n","        super(SRCNN, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=num_channels,\n","                               out_channels=64,\n","                               kernel_size=9,\n","                               padding=9 // 2)\n","        self.conv2 = nn.Conv2d(in_channels=64,\n","                               out_channels=32,\n","                               kernel_size=5,\n","                               padding=5 // 2)\n","        self.conv3 = nn.Conv2d(in_channels=32, \n","                               out_channels=num_channels, \n","                               kernel_size=5,\n","                               padding=5 // 2)\n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.conv3(x)\n","        \n","        return x\n","\n","model = SRCNN().to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{"id":"xf1j1c-ppcy3"},"source":["## 6. 정확도 측정 함수 (PSNR) 선언\n","PSNR: [wiki](https://ko.wikipedia.org/wiki/%EC%B5%9C%EB%8C%80_%EC%8B%A0%ED%98%B8_%EB%8C%80_%EC%9E%A1%EC%9D%8C%EB%B9%84)\n","\n","$\\textrm{PSNR}=10\\cdot\\log{\\left(\\frac{\\textrm{MAX}^2}{\\textrm{MSE}}\\right)}$\n","\n","$\\textrm{MAX}$: tensor가 가질 수 있는 최대값\n","\n","$\\textrm{MSE}$: Mean square error"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmZPenGBpcy3"},"outputs":[],"source":["def calculate_psnr(image1, image2):\n","    max_val = 1.\n","    mse = torch.mean((image1 - image2) ** 2)\n","    psnr = 10. * torch.log10((max_val ** 2) / mse)\n","    return psnr.item()"]},{"cell_type":"markdown","metadata":{"id":"FvcCdIkdpcy4"},"source":["## 7. Dataset, data loader 선언"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":388,"status":"error","timestamp":1654669589909,"user":{"displayName":"김승욱","userId":"08177621807583907944"},"user_tz":-540},"id":"-txnVldIpcy4","colab":{"base_uri":"https://localhost:8080/","height":376},"outputId":"a2d5bf39-71c0-402d-a343-40e523417e9b"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-39a689b7ffe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m                           \u001b[0minput_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                           db_type='train')\n\u001b[0m\u001b[1;32m     79\u001b[0m train_dataloader = DataLoader(dataset=train_dataset,\n\u001b[1;32m     80\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-39a689b7ffe5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, input_transform, target_transform, db_type)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         self.lr_list = [\n\u001b[0;32m---> 13\u001b[0;31m             os.path.join(lr_dir, f) for f in os.listdir(lr_dir)]\n\u001b[0m\u001b[1;32m     14\u001b[0m         self.hr_list = [\n\u001b[1;32m     15\u001b[0m             os.path.join(hr_dir, f) for f in os.listdir(hr_dir)]\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ai_intro/SRCNN/DB/train/lr/'"]}],"source":["class SRDataset(Dataset):\n","    def __init__(self, \n","                 image_dir,\n","                 input_transform=None, \n","                 target_transform=None, \n","                 db_type='train'):\n","        super(SRDataset, self).__init__()\n","        \n","        lr_dir = os.path.join(image_dir, \"lr/\")     # low-resolution image (input)\n","        hr_dir = os.path.join(image_dir, \"hr/\")     # high-resolution image (label)\n","        \n","        self.lr_list = [\n","            os.path.join(lr_dir, f) for f in os.listdir(lr_dir)]\n","        self.hr_list = [\n","            os.path.join(hr_dir, f) for f in os.listdir(hr_dir)]\n","        \n","        self.lr_list.sort()\n","        self.hr_list.sort()\n","        \n","        total_len = len(self.hr_list)\n","        train_len = round(total_len * 0.9)\n","        \n","        self.input_transform = input_transform\n","        self.target_transform = target_transform\n","        \n","        self.db_type = db_type\n","        \n","        if self.db_type is 'train':\n","            self.lr_list = self.lr_list[:train_len]\n","            self.hr_list = self.hr_list[:train_len]\n","        elif self.db_type is 'val':\n","            self.lr_list = self.lr_list[train_len:]\n","            self.hr_list = self.hr_list[train_len:]\n","\n","        self.crop_size = 33\n","\n","    def __getitem__(self, idx):\n","        lr_image = pil_image.open(self.lr_list[idx])\n","        hr_image = pil_image.open(self.hr_list[idx])\n","        \n","        # Transform images\n","        if self.input_transform is not None:\n","            lr_image = self.input_transform(lr_image)\n","        \n","        if self.target_transform is not None:\n","            hr_image = self.target_transform(hr_image)\n","\n","        if self.db_type is 'train':\n","            # Random crop\n","            lr_image, hr_image = self.random_crop(lr_image, hr_image)\n","        \n","        return lr_image, hr_image\n","            \n","    def random_crop(self, input, target):\n","        h = input.size(-2)\n","        w = input.size(-1)\n","                \n","        rand_h = torch.randint(h - self.crop_size, [1, 1])\n","        rand_w = torch.randint(w - self.crop_size, [1, 1])\n","        \n","        input = input[:, rand_h:rand_h + self.crop_size, rand_w:rand_w + self.crop_size]\n","        target = target[:, rand_h:rand_h + self.crop_size, rand_w:rand_w + self.crop_size]\n","        \n","        return input, target\n","        \n","    def __len__(self):\n","        return len(self.hr_list)\n","\n","\n","input_transform = transforms.Compose(\n","                    [transforms.ToTensor()])\n","target_transform = transforms.Compose(\n","                    [transforms.ToTensor()])\n","\n","train_dataset = SRDataset(train_db_dir,\n","                          input_transform=input_transform,\n","                          target_transform=target_transform,\n","                          db_type='train')\n","train_dataloader = DataLoader(dataset=train_dataset,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=num_workers,\n","                              drop_last=True)\n","val_dataset = SRDataset(train_db_dir, \n","                        input_transform=input_transform,\n","                        target_transform=target_transform,\n","                        db_type='val')\n","val_dataloader = DataLoader(dataset=val_dataset,\n","                            batch_size=1,\n","                            shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"-MuGFOETpcy5"},"source":["## 8. Training & validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nx41ro3Tpcy5"},"outputs":[],"source":["best_epoch = 0\n","best_psnr = 0.0\n","\n","num_train = len(train_dataset) // batch_size\n","\n","# writer = SummaryWriter(log_dir='./log')\n","\n","start_t = time.time()\n","for epoch in range(num_epochs):\n","    model.train()\n","    \n","    loss_arr = []\n","    \n","    for iter, (inputs, labels) in enumerate(train_dataloader):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        preds = model(inputs)     # net.forward(input)\n","        \n","        loss = criterion(preds, labels)\n","\n","        optimizer.zero_grad()   # G = 0 \n","\n","        loss.backward()     # 그라디언트를 계산\n","\n","        optimizer.step()    # 그라디언트를 사용하여 파라미터를 업데이트\n","\n","        loss_arr += [loss.item()]\n","       \n","        if iter % 20 == 0:\n","            elapsed_time = time.time() - start_t\n","            print('TRAIN(Elapsed: %fs): EPOCH %d/%d | BATCH %d/%d | LOSS: %f' %\n","                (elapsed_time, epoch+1, num_epochs, iter+1, num_train, np.mean(loss_arr)))\n","            start_t = time.time()\n","        \n","    save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='{}'.format(epoch+1))\n","    \n","    model.eval()\n","    psnr_arr = []\n","    \n","    for n, (input, label) in enumerate(val_dataloader):\n","        input, label = input.to(device), label.to(device)\n","        \n","        with torch.no_grad():\n","            preds = model(input)\n","            preds = preds.clamp(0.0, 1.0)\n","            \n","        psnr = calculate_psnr(preds, label)\n","        psnr_arr.append(psnr)\n","    \n","    epoch_psnr = np.mean(psnr_arr)\n","    print('PSNR(epoch: %d): %f' % (epoch+1, epoch_psnr))\n","    \n","    if epoch_psnr > best_psnr:\n","        best_psnr = epoch_psnr\n","        best_epoch = epoch\n","        save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='_best')\n","    \n","    # # Log on tensorboard\n","    # writer.add_scalar('loss', np.mean(loss_arr), epoch)\n","    # writer.add_scalar('psnr', epoch_psnr, epoch)\n","        \n","# writer.close\n","print('best epoch: {}, psnr: {}'.format(best_epoch, best_psnr))\n","save(ckpt_dir=ckpt_dir, net=model, optim=optimizer, postfix='_best')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"114AKw0Bt9pS"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[]},"interpreter":{"hash":"61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"},"kernelspec":{"display_name":"Python 3.7.13 ('pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"}},"nbformat":4,"nbformat_minor":0}