{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch를 이용한 간단한 CNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    # Pytorch 기본 라이브러리\n",
    "import torch.nn as nn   # Neural Network (nn)에 관련된 모듈들\n",
    "from torch.utils.data import DataLoader # Database의 데이터들을 불러오기 위한 라이브러리\n",
    "\n",
    "from torchvision import transforms, datasets    # 불러온 입력을 처리하는 모듈들\n",
    "\n",
    "import os   # 경로 탐색, 접근 등을 처리하기 위한 라이브러리\n",
    "import numpy as np # 행렬 연산에 사용하는 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 평가를 위한 하이퍼 파리미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "ckpt_dir = './checkpoint'   # 학습된 파라미터를 저장할 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):       # nn.Module를 상속받아서 사용.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # 상속해준 부모 클래스의 Method를 사용할 때 super(하위클래스, 하위클래스의 객체)\n",
    "\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, \n",
    "                               out_channels=10, \n",
    "                               kernel_size=5, \n",
    "                               stride=1, \n",
    "                               padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)    # cf. AvgPool2d\n",
    "\n",
    "        # Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, \n",
    "                               out_channels=20, \n",
    "                               kernel_size=5, \n",
    "                               stride=1, \n",
    "                               padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)    # H * W * C = 320\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=320, \n",
    "                             out_features=50)             # Fully-Connected Layer\n",
    "        self.relu1_fc1 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):   # x: 입력영상 (torch.Tensor())\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 320)     # x: B=128, C=20, H=4, W=4\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1_fc1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습된 파라미터를 저장하거나 불러오는 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ckpt_dir, net, optim, epoch):      # ckpt_dir: checkpoint를 저장할 경로, net, optim, epoch\n",
    "    if not os.path.exists(ckpt_dir):    # ckpt_dir이 존재하는지 확인하는 함수\n",
    "        os.makedirs(ckpt_dir)           # 디렉토리를 만들어주는 함수\n",
    "\n",
    "    torch.save({'net': net.state_dict(),        # 네트워크에 있는 변수들\n",
    "                'optim': optim.state_dict()},   # optimizer에 있는 변수들\n",
    "               './%s/model_epoch%d.pth' % (ckpt_dir, epoch))\n",
    "\n",
    "def load(ckpt_dir, net, optim=None):\n",
    "    ckpt_lst = os.listdir(ckpt_dir)  # 입력한 디렉토리 내의 모든 파일과 디렉토리의 리스트를 반환\n",
    "    ckpt_lst.sort()  # 정렬\n",
    "\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    \n",
    "    if optim is not None:\n",
    "        optim.load_state_dict(dict_model['optim'])\n",
    "\n",
    "    return net, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Database 불러오기\n",
    "### Database가 없을 경우 Pytorch에 내장되어 있는 MNIST 다운로드 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "\n",
    "dataset = datasets.MNIST(download=True, \n",
    "                         root='./', \n",
    "                         train=False, \n",
    "                         transform=transform)   # 개별 데이터 파일의 처리를 담당\n",
    "loader = DataLoader(dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=False, \n",
    "                    num_workers=0)  # 미니배치 처리를 담당\n",
    "\n",
    "num_data = len(loader.dataset)\n",
    "num_batch = num_data // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 네트워크 및 평가함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "\n",
    "fn_loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def fn_pred(output):\n",
    "    return torch.softmax(output, dim=1)     # B=128 (dim=0), 10 (dim=1)\n",
    "\n",
    "def fn_accuracy(pred, label):\n",
    "    return (pred.max(dim=1)[1] == label).type(torch.float).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: BATCH 0001/0078 | LOSS: 0.0515 | ACC 0.9922\n",
      "TEST: BATCH 0002/0078 | LOSS: 0.0599 | ACC 0.9883\n",
      "TEST: BATCH 0003/0078 | LOSS: 0.0936 | ACC 0.9740\n",
      "TEST: BATCH 0004/0078 | LOSS: 0.0993 | ACC 0.9727\n",
      "TEST: BATCH 0005/0078 | LOSS: 0.1035 | ACC 0.9688\n",
      "TEST: BATCH 0006/0078 | LOSS: 0.1104 | ACC 0.9648\n",
      "TEST: BATCH 0007/0078 | LOSS: 0.1063 | ACC 0.9676\n",
      "TEST: BATCH 0008/0078 | LOSS: 0.1157 | ACC 0.9629\n",
      "TEST: BATCH 0009/0078 | LOSS: 0.1204 | ACC 0.9583\n",
      "TEST: BATCH 0010/0078 | LOSS: 0.1378 | ACC 0.9555\n",
      "TEST: BATCH 0011/0078 | LOSS: 0.1426 | ACC 0.9545\n",
      "TEST: BATCH 0012/0078 | LOSS: 0.1466 | ACC 0.9531\n",
      "TEST: BATCH 0013/0078 | LOSS: 0.1445 | ACC 0.9543\n",
      "TEST: BATCH 0014/0078 | LOSS: 0.1494 | ACC 0.9542\n",
      "TEST: BATCH 0015/0078 | LOSS: 0.1460 | ACC 0.9557\n",
      "TEST: BATCH 0016/0078 | LOSS: 0.1498 | ACC 0.9551\n",
      "TEST: BATCH 0017/0078 | LOSS: 0.1516 | ACC 0.9540\n",
      "TEST: BATCH 0018/0078 | LOSS: 0.1577 | ACC 0.9531\n",
      "TEST: BATCH 0019/0078 | LOSS: 0.1587 | ACC 0.9531\n",
      "TEST: BATCH 0020/0078 | LOSS: 0.1549 | ACC 0.9543\n",
      "TEST: BATCH 0021/0078 | LOSS: 0.1545 | ACC 0.9554\n",
      "TEST: BATCH 0022/0078 | LOSS: 0.1509 | ACC 0.9563\n",
      "TEST: BATCH 0023/0078 | LOSS: 0.1496 | ACC 0.9562\n",
      "TEST: BATCH 0024/0078 | LOSS: 0.1505 | ACC 0.9551\n",
      "TEST: BATCH 0025/0078 | LOSS: 0.1496 | ACC 0.9553\n",
      "TEST: BATCH 0026/0078 | LOSS: 0.1477 | ACC 0.9564\n",
      "TEST: BATCH 0027/0078 | LOSS: 0.1464 | ACC 0.9563\n",
      "TEST: BATCH 0028/0078 | LOSS: 0.1473 | ACC 0.9562\n",
      "TEST: BATCH 0029/0078 | LOSS: 0.1466 | ACC 0.9569\n",
      "TEST: BATCH 0030/0078 | LOSS: 0.1508 | ACC 0.9552\n",
      "TEST: BATCH 0031/0078 | LOSS: 0.1521 | ACC 0.9544\n",
      "TEST: BATCH 0032/0078 | LOSS: 0.1524 | ACC 0.9541\n",
      "TEST: BATCH 0033/0078 | LOSS: 0.1517 | ACC 0.9543\n",
      "TEST: BATCH 0034/0078 | LOSS: 0.1526 | ACC 0.9540\n",
      "TEST: BATCH 0035/0078 | LOSS: 0.1512 | ACC 0.9545\n",
      "TEST: BATCH 0036/0078 | LOSS: 0.1512 | ACC 0.9546\n",
      "TEST: BATCH 0037/0078 | LOSS: 0.1499 | ACC 0.9552\n",
      "TEST: BATCH 0038/0078 | LOSS: 0.1507 | ACC 0.9552\n",
      "TEST: BATCH 0039/0078 | LOSS: 0.1521 | ACC 0.9543\n",
      "TEST: BATCH 0040/0078 | LOSS: 0.1490 | ACC 0.9553\n",
      "TEST: BATCH 0041/0078 | LOSS: 0.1463 | ACC 0.9562\n",
      "TEST: BATCH 0042/0078 | LOSS: 0.1445 | ACC 0.9567\n",
      "TEST: BATCH 0043/0078 | LOSS: 0.1415 | ACC 0.9577\n",
      "TEST: BATCH 0044/0078 | LOSS: 0.1392 | ACC 0.9585\n",
      "TEST: BATCH 0045/0078 | LOSS: 0.1385 | ACC 0.9589\n",
      "TEST: BATCH 0046/0078 | LOSS: 0.1371 | ACC 0.9591\n",
      "TEST: BATCH 0047/0078 | LOSS: 0.1374 | ACC 0.9589\n",
      "TEST: BATCH 0048/0078 | LOSS: 0.1369 | ACC 0.9591\n",
      "TEST: BATCH 0049/0078 | LOSS: 0.1353 | ACC 0.9597\n",
      "TEST: BATCH 0050/0078 | LOSS: 0.1328 | ACC 0.9605\n",
      "TEST: BATCH 0051/0078 | LOSS: 0.1316 | ACC 0.9611\n",
      "TEST: BATCH 0052/0078 | LOSS: 0.1342 | ACC 0.9599\n",
      "TEST: BATCH 0053/0078 | LOSS: 0.1330 | ACC 0.9602\n",
      "TEST: BATCH 0054/0078 | LOSS: 0.1316 | ACC 0.9605\n",
      "TEST: BATCH 0055/0078 | LOSS: 0.1298 | ACC 0.9611\n",
      "TEST: BATCH 0056/0078 | LOSS: 0.1282 | ACC 0.9615\n",
      "TEST: BATCH 0057/0078 | LOSS: 0.1270 | ACC 0.9619\n",
      "TEST: BATCH 0058/0078 | LOSS: 0.1250 | ACC 0.9626\n",
      "TEST: BATCH 0059/0078 | LOSS: 0.1244 | ACC 0.9627\n",
      "TEST: BATCH 0060/0078 | LOSS: 0.1228 | ACC 0.9633\n",
      "TEST: BATCH 0061/0078 | LOSS: 0.1212 | ACC 0.9639\n",
      "TEST: BATCH 0062/0078 | LOSS: 0.1204 | ACC 0.9640\n",
      "TEST: BATCH 0063/0078 | LOSS: 0.1188 | ACC 0.9645\n",
      "TEST: BATCH 0064/0078 | LOSS: 0.1180 | ACC 0.9648\n",
      "TEST: BATCH 0065/0078 | LOSS: 0.1168 | ACC 0.9654\n",
      "TEST: BATCH 0066/0078 | LOSS: 0.1157 | ACC 0.9658\n",
      "TEST: BATCH 0067/0078 | LOSS: 0.1142 | ACC 0.9663\n",
      "TEST: BATCH 0068/0078 | LOSS: 0.1127 | ACC 0.9668\n",
      "TEST: BATCH 0069/0078 | LOSS: 0.1111 | ACC 0.9673\n",
      "TEST: BATCH 0070/0078 | LOSS: 0.1097 | ACC 0.9677\n",
      "TEST: BATCH 0071/0078 | LOSS: 0.1111 | ACC 0.9675\n",
      "TEST: BATCH 0072/0078 | LOSS: 0.1097 | ACC 0.9680\n",
      "TEST: BATCH 0073/0078 | LOSS: 0.1086 | ACC 0.9684\n",
      "TEST: BATCH 0074/0078 | LOSS: 0.1073 | ACC 0.9688\n",
      "TEST: BATCH 0075/0078 | LOSS: 0.1064 | ACC 0.9690\n",
      "TEST: BATCH 0076/0078 | LOSS: 0.1066 | ACC 0.9688\n",
      "TEST: BATCH 0077/0078 | LOSS: 0.1079 | ACC 0.9684\n",
      "TEST: BATCH 0078/0078 | LOSS: 0.1092 | ACC 0.9680\n",
      "TEST: BATCH 0079/0078 | LOSS: 0.1080 | ACC 0.9685\n"
     ]
    }
   ],
   "source": [
    "num_data = len(loader.dataset)\n",
    "num_batch = num_data // batch_size\n",
    "\n",
    "net, _ = load(ckpt_dir=ckpt_dir, net=net)\n",
    "\n",
    "## 평가 시작하기\n",
    "with torch.no_grad():\n",
    "    # net.train()\n",
    "    net.eval()\n",
    "\n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "\n",
    "    for batch, (input, label) in enumerate(loader, 1):\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = net(input)\n",
    "        pred = fn_pred(output)\n",
    "\n",
    "        loss = fn_loss(output, label)\n",
    "        acc = fn_accuracy(pred, label)\n",
    "\n",
    "        loss_arr += [loss.item()]\n",
    "        acc_arr += [acc.item()]\n",
    "\n",
    "        print('TEST: BATCH %04d/%04d | LOSS: %.4f | ACC %.4f' %\n",
    "              (batch, num_batch, np.mean(loss_arr), np.mean(acc_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb0112c456f82d9d2ffc2ba40e932c79270a28c5f552c1ea081145b825aa262c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
